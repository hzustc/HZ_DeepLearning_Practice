{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:08.186801Z",
     "start_time": "2024-12-21T04:40:08.181835Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c455e16d805dfdfb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:08.502481Z",
     "start_time": "2024-12-21T04:40:08.484380Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "新闻热度的召回 最后一次点击前后一小时\n",
    "itemcf 改进\n",
    "word2vec召回\n",
    "\n"
   ],
   "id": "c0f0769d771a8d5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:10.371993Z",
     "start_time": "2024-12-21T04:40:08.533377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from tqdm import tqdm  \n",
    "from collections import defaultdict  \n",
    "import os, math, warnings, math, pickle\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "import collections\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "id": "7cea84c244c2a9e8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:10.386993Z",
     "start_time": "2024-12-21T04:40:10.376994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = './data_raw/'\n",
    "save_path = './tmp_results/'\n",
    "# 做召回评估的一个标志, 如果不进行评估就是直接使用全量数据进行召回\n",
    "metric_recall = True\n"
   ],
   "id": "2f5e80ebe39e8777",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:10.401993Z",
     "start_time": "2024-12-21T04:40:10.388994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# debug模式： 从训练集中划出一部分数据来调试代码\n",
    "def get_all_click_sample(data_path='./data_raw/', sample_nums=10000):\n",
    "    \"\"\"\n",
    "        训练集中采样一部分数据调试\n",
    "        data_path: 原数据的存储路径\n",
    "        sample_nums: 采样数目（这里由于机器的内存限制，可以采样用户做）\n",
    "    \"\"\"\n",
    "    all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    all_user_ids = all_click.user_id.unique()\n",
    "\n",
    "    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False) \n",
    "    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click\n",
    "\n",
    "# 读取点击数据，这里分成线上和线下，如果是为了获取线上提交结果应该讲测试集中的点击数据合并到总的数据中\n",
    "# 如果是为了线下验证模型的有效性或者特征的有效性，可以只使用训练集\n",
    "def get_all_click_df(data_path='./data_raw/', offline=True):\n",
    "    if offline:\n",
    "        all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    else:\n",
    "        trn_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "\n",
    "        all_click = trn_click.append(tst_click)\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click\n"
   ],
   "id": "998abe1e096e46a3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:10.417993Z",
     "start_time": "2024-12-21T04:40:10.403993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 读取文章的基本属性\n",
    "def get_item_info_df(data_path):\n",
    "    item_info_df = pd.read_csv(data_path + 'articles.csv')\n",
    "    \n",
    "    # 为了方便与训练集中的click_article_id拼接，需要把article_id修改成click_article_id\n",
    "    item_info_df = item_info_df.rename(columns={'article_id': 'click_article_id'})\n",
    "    \n",
    "    return item_info_df\n"
   ],
   "id": "bfbd8e7b17b28aac",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:10.433993Z",
     "start_time": "2024-12-21T04:40:10.418992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 读取文章的Embedding数据\n",
    "def get_item_emb_dict(data_path):\n",
    "    item_emb_df = pd.read_csv(data_path + 'articles_emb.csv')\n",
    "    \n",
    "    item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]\n",
    "    item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols])\n",
    "    # 进行归一化\n",
    "    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)\n",
    "\n",
    "    item_emb_dict = dict(zip(item_emb_df['article_id'], item_emb_np))\n",
    "    pickle.dump(item_emb_dict, open(save_path + 'item_content_emb.pkl', 'wb'))\n",
    "    \n",
    "    return item_emb_dict\n"
   ],
   "id": "56ba65755357dd7b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:10.449991Z",
     "start_time": "2024-12-21T04:40:10.435992Z"
    }
   },
   "cell_type": "code",
   "source": "max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
   "id": "f3d63944fee8caf0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "新闻热度召回",
   "id": "e54304e10ccf4038"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:10.465991Z",
     "start_time": "2024-12-21T04:40:10.450992Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3c3a340e48db30c9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:11.162338Z",
     "start_time": "2024-12-21T04:40:10.466991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 采样数据\n",
    "all_click_df = get_all_click_sample(data_path)\n",
    "\n",
    "# 全量训练集\n",
    "# all_click_df = get_all_click_df(offline=False)\n",
    "\n",
    "# 对时间戳进行归一化,用于在关联规则的时候计算权重\n",
    "all_click_df['click_timestamp'] = all_click_df[['click_timestamp']].apply(max_min_scaler)\n"
   ],
   "id": "55a19359906894ed",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:11.306331Z",
     "start_time": "2024-12-21T04:40:11.165335Z"
    }
   },
   "cell_type": "code",
   "source": "item_info_df = get_item_info_df(data_path)\n",
   "id": "2f60a5b0f4fbddd4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.301116Z",
     "start_time": "2024-12-21T04:40:11.310336Z"
    }
   },
   "cell_type": "code",
   "source": "item_emb_dict = get_item_emb_dict(data_path)\n",
   "id": "8d23fb5c5b4e23ff",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.317093Z",
     "start_time": "2024-12-21T04:40:24.302092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 根据点击时间获取用户的点击文章序列   {user1: [item1: time1, item2: time2..]...}\n",
    "def get_user_item_time(click_df):\n",
    "    \n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    \n",
    "    def make_item_time_pair(df):\n",
    "        return list(zip(df['click_article_id'], df['click_timestamp']))\n",
    "    \n",
    "    user_item_time_df = click_df.groupby('user_id')['click_article_id', 'click_timestamp'].apply(lambda x: make_item_time_pair(x))\\\n",
    "                                                            .reset_index().rename(columns={0: 'item_time_list'})\n",
    "    user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n",
    "    \n",
    "    return user_item_time_dict\n"
   ],
   "id": "3bf5f7d1b3776610",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.332408Z",
     "start_time": "2024-12-21T04:40:24.318304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 根据时间获取商品被点击的用户序列  {item1: [user1: time1, user2: time2...]...}\n",
    "# 这里的时间是用户点击当前商品的时间，好像没有直接的关系。\n",
    "def get_item_user_time_dict(click_df):\n",
    "    def make_user_time_pair(df):\n",
    "        return list(zip(df['user_id'], df['click_timestamp']))\n",
    "    \n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    item_user_time_df = click_df.groupby('click_article_id')['user_id', 'click_timestamp'].apply(lambda x: make_user_time_pair(x))\\\n",
    "                                                            .reset_index().rename(columns={0: 'user_time_list'})\n",
    "    \n",
    "    item_user_time_dict = dict(zip(item_user_time_df['click_article_id'], item_user_time_df['user_time_list']))\n",
    "    return item_user_time_dict\n"
   ],
   "id": "73ff9ebd34452ba",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.347593Z",
     "start_time": "2024-12-21T04:40:24.333569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取当前数据的历史点击和最后一次点击\n",
    "def get_hist_and_last_click(all_click):\n",
    "    \n",
    "    all_click = all_click.sort_values(by=['user_id', 'click_timestamp'])\n",
    "    click_last_df = all_click.groupby('user_id').tail(1)\n",
    "\n",
    "    # 如果用户只有一个点击，hist为空了，会导致训练的时候这个用户不可见，此时默认泄露一下\n",
    "    def hist_func(user_df):\n",
    "        if len(user_df) == 1:\n",
    "            return user_df\n",
    "        else:\n",
    "            return user_df[:-1]\n",
    "\n",
    "    click_hist_df = all_click.groupby('user_id').apply(hist_func).reset_index(drop=True)\n",
    "\n",
    "    return click_hist_df, click_last_df\n"
   ],
   "id": "154972ea014a73d8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.363579Z",
     "start_time": "2024-12-21T04:40:24.348577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取文章id对应的基本属性，保存成字典的形式，方便后面召回阶段，冷启动阶段直接使用\n",
    "def get_item_info_dict(item_info_df):\n",
    "    max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    item_info_df['created_at_ts'] = item_info_df[['created_at_ts']].apply(max_min_scaler)\n",
    "    \n",
    "    item_type_dict = dict(zip(item_info_df['click_article_id'], item_info_df['category_id']))\n",
    "    item_words_dict = dict(zip(item_info_df['click_article_id'], item_info_df['words_count']))\n",
    "    item_created_time_dict = dict(zip(item_info_df['click_article_id'], item_info_df['created_at_ts']))\n",
    "    \n",
    "    return item_type_dict, item_words_dict, item_created_time_dict\n"
   ],
   "id": "de61471f19e09b2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.379578Z",
     "start_time": "2024-12-21T04:40:24.364576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_user_hist_item_info_dict(all_click):\n",
    "    \n",
    "    # 获取user_id对应的用户历史点击文章类型的集合字典\n",
    "    user_hist_item_typs = all_click.groupby('user_id')['category_id'].agg(set).reset_index()\n",
    "    user_hist_item_typs_dict = dict(zip(user_hist_item_typs['user_id'], user_hist_item_typs['category_id']))\n",
    "    \n",
    "    # 获取user_id对应的用户点击文章的集合\n",
    "    user_hist_item_ids_dict = all_click.groupby('user_id')['click_article_id'].agg(set).reset_index()\n",
    "    user_hist_item_ids_dict = dict(zip(user_hist_item_ids_dict['user_id'], user_hist_item_ids_dict['click_article_id']))\n",
    "    \n",
    "    # 获取user_id对应的用户历史点击的文章的平均字数字典\n",
    "    user_hist_item_words = all_click.groupby('user_id')['words_count'].agg('mean').reset_index()\n",
    "    user_hist_item_words_dict = dict(zip(user_hist_item_words['user_id'], user_hist_item_words['words_count']))\n",
    "    \n",
    "    # 获取user_id对应的用户最后一次点击的文章的创建时间\n",
    "    all_click_ = all_click.sort_values('click_timestamp')\n",
    "    user_last_item_created_time = all_click_.groupby('user_id')['created_at_ts'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "    \n",
    "    max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    user_last_item_created_time['created_at_ts'] = user_last_item_created_time[['created_at_ts']].apply(max_min_scaler)\n",
    "    \n",
    "    user_last_item_created_time_dict = dict(zip(user_last_item_created_time['user_id'], \\\n",
    "                                                user_last_item_created_time['created_at_ts']))\n",
    "    \n",
    "    return user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict\n"
   ],
   "id": "8fab9cd2475bb3b0",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.395616Z",
     "start_time": "2024-12-21T04:40:24.380610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取近期点击最多的文章\n",
    "def get_item_topk_click(click_df, k):\n",
    "    topk_click = click_df['click_article_id'].value_counts().index[:k]\n",
    "    return topk_click\n"
   ],
   "id": "f24f9deefda065cf",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.555620Z",
     "start_time": "2024-12-21T04:40:24.396615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取文章的属性信息，保存成字典的形式方便查询\n",
    "item_type_dict, item_words_dict, item_created_time_dict = get_item_info_dict(item_info_df)\n"
   ],
   "id": "7fa0b66b23d08ea4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:24.571672Z",
     "start_time": "2024-12-21T04:40:24.557621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义一个多路召回的字典，将各路召回的结果都保存在这个字典当中\n",
    "user_multi_recall_dict =  {'itemcf_sim_itemcf_recall': {},\n",
    "                           'embedding_sim_item_recall': {},\n",
    "                           }\n"
   ],
   "id": "d1867d4d99663d30",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:26.210492Z",
     "start_time": "2024-12-21T04:40:24.573669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 提取最后一次点击作为召回评估，如果不需要做召回评估直接使用全量的训练集进行召回(线下验证模型)\n",
    "# 如果不是召回评估，直接使用全量数据进行召回，不用将最后一次提取出来\n",
    "trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n"
   ],
   "id": "34b75016007c2395",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:26.226013Z",
     "start_time": "2024-12-21T04:40:26.212492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 依次评估召回的前10, 20, 30, 40, 50个文章中的击中率\n",
    "def metrics_recall(user_recall_items_dict, trn_last_click_df, topk=5):\n",
    "    last_click_item_dict = dict(zip(trn_last_click_df['user_id'], trn_last_click_df['click_article_id']))\n",
    "    user_num = len(user_recall_items_dict)\n",
    "    \n",
    "    for k in range(10, topk+1, 10):\n",
    "        hit_num = 0\n",
    "        for user, item_list in user_recall_items_dict.items():\n",
    "            # 获取前k个召回的结果\n",
    "            tmp_recall_items = [x[0] for x in user_recall_items_dict[user][:k]]\n",
    "            if last_click_item_dict[user] in set(tmp_recall_items):\n",
    "                hit_num += 1\n",
    "        \n",
    "        hit_rate = round(hit_num * 1.0 / user_num, 5)\n",
    "        print(' topk: ', k, ' : ', 'hit_num: ', hit_num, 'hit_rate: ', hit_rate, 'user_num : ', user_num)\n"
   ],
   "id": "24dfeda80e3a2fa7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:26.242014Z",
     "start_time": "2024-12-21T04:40:26.228013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def itemcf_sim(df, item_created_time_dict):\n",
    "    \"\"\"\n",
    "        文章与文章之间的相似性矩阵计算\n",
    "        :param df: 数据表\n",
    "        :item_created_time_dict:  文章创建时间的字典\n",
    "        return : 文章与文章的相似性矩阵\n",
    "        \n",
    "        思路: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习) + 关联规则\n",
    "    \"\"\"\n",
    "    \n",
    "    user_item_time_dict = get_user_item_time(df)\n",
    "    \n",
    "    # 计算物品相似度\n",
    "    i2i_sim = {}\n",
    "    item_cnt = defaultdict(int)\n",
    "    for user, item_time_list in tqdm(user_item_time_dict.items()):\n",
    "        # 在基于商品的协同过滤优化的时候可以考虑时间因素\n",
    "        for loc1, (i, i_click_time) in enumerate(item_time_list):\n",
    "            item_cnt[i] += 1\n",
    "            i2i_sim.setdefault(i, {})\n",
    "            for loc2, (j, j_click_time) in enumerate(item_time_list):\n",
    "                if(i == j):\n",
    "                    continue\n",
    "                    \n",
    "                # 考虑文章的正向顺序点击和反向顺序点击    \n",
    "                loc_alpha = 1.0 if loc2 > loc1 else 0.7\n",
    "                # 位置信息权重，其中的参数可以调节\n",
    "                loc_weight = loc_alpha * (0.9 ** (np.abs(loc2 - loc1) - 1))\n",
    "                # 点击时间权重，其中的参数可以调节\n",
    "                click_time_weight = np.exp(0.7 ** np.abs(i_click_time - j_click_time))\n",
    "                # 两篇文章创建时间的权重，其中的参数可以调节\n",
    "                created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "                i2i_sim[i].setdefault(j, 0)\n",
    "                # 考虑多种因素的权重计算最终的文章之间的相似度\n",
    "                i2i_sim[i][j] += loc_weight * click_time_weight * created_time_weight / math.log(len(item_time_list) + 1)\n",
    "                \n",
    "    i2i_sim_ = i2i_sim.copy()\n",
    "    for i, related_items in i2i_sim.items():\n",
    "        for j, wij in related_items.items():\n",
    "            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "    \n",
    "    # 将得到的相似性矩阵保存到本地\n",
    "    pickle.dump(i2i_sim_, open(save_path + 'itemcf_i2i_sim.pkl', 'wb'))\n",
    "    \n",
    "    return i2i_sim_\n"
   ],
   "id": "aa2c241df3d23508",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:30.125134Z",
     "start_time": "2024-12-21T04:40:26.244013Z"
    }
   },
   "cell_type": "code",
   "source": "i2i_sim = itemcf_sim(trn_hist_click_df, item_created_time_dict)\n",
   "id": "888956307a79d476",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 3492.30it/s]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:30.140637Z",
     "start_time": "2024-12-21T04:40:30.126016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_user_activate_degree_dict(all_click_df):\n",
    "    all_click_df_ = all_click_df.groupby('user_id')['click_article_id'].count().reset_index()\n",
    "    \n",
    "    # 用户活跃度归一化\n",
    "    mm = MinMaxScaler()\n",
    "    all_click_df_['click_article_id'] = mm.fit_transform(all_click_df_[['click_article_id']])\n",
    "    user_activate_degree_dict = dict(zip(all_click_df_['user_id'], all_click_df_['click_article_id']))\n",
    "    \n",
    "    return user_activate_degree_dict\n"
   ],
   "id": "d5f656497a7fcbf2",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:30.156640Z",
     "start_time": "2024-12-21T04:40:30.141638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def usercf_sim(all_click_df, user_activate_degree_dict):\n",
    "    \"\"\"\n",
    "        用户相似性矩阵计算\n",
    "        :param all_click_df: 数据表\n",
    "        :param user_activate_degree_dict: 用户活跃度的字典\n",
    "        return 用户相似性矩阵\n",
    "        \n",
    "        思路: 基于用户的协同过滤(详细请参考上一期推荐系统基础的组队学习) + 关联规则\n",
    "    \"\"\"\n",
    "    item_user_time_dict = get_item_user_time_dict(all_click_df)\n",
    "    \n",
    "    u2u_sim = {}\n",
    "    user_cnt = defaultdict(int)\n",
    "    for item, user_time_list in tqdm(item_user_time_dict.items()):\n",
    "        for u, click_time in user_time_list:\n",
    "            user_cnt[u] += 1\n",
    "            u2u_sim.setdefault(u, {})\n",
    "            for v, click_time in user_time_list:\n",
    "                u2u_sim[u].setdefault(v, 0)\n",
    "                if u == v:\n",
    "                    continue\n",
    "                # 用户平均活跃度作为活跃度的权重，这里的式子也可以改善\n",
    "                activate_weight = 100 * 0.5 * (user_activate_degree_dict[u] + user_activate_degree_dict[v])   \n",
    "                u2u_sim[u][v] += activate_weight / math.log(len(user_time_list) + 1)\n",
    "    \n",
    "    u2u_sim_ = u2u_sim.copy()\n",
    "    for u, related_users in u2u_sim.items():\n",
    "        for v, wij in related_users.items():\n",
    "            u2u_sim_[u][v] = wij / math.sqrt(user_cnt[u] * user_cnt[v])\n",
    "    \n",
    "    # 将得到的相似性矩阵保存到本地\n",
    "    pickle.dump(u2u_sim_, open(save_path + 'usercf_u2u_sim.pkl', 'wb'))\n",
    "\n",
    "    return u2u_sim_\n"
   ],
   "id": "249c64184d99a462",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:33.972150Z",
     "start_time": "2024-12-21T04:40:30.158639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 由于usercf计算时候太耗费内存了，这里就不直接运行了\n",
    "# 如果是采样的话，是可以运行的\n",
    "user_activate_degree_dict = get_user_activate_degree_dict(trn_hist_click_df)\n",
    "u2u_sim = usercf_sim(trn_hist_click_df, user_activate_degree_dict)\n"
   ],
   "id": "a79dcaf7ce0ea114",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5732/5732 [00:02<00:00, 2335.60it/s]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:40:33.987516Z",
     "start_time": "2024-12-21T04:40:33.975508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 向量检索相似度计算\n",
    "# topk指的是每个item, faiss搜索后返回最相似的topk个item\n",
    "def embdding_sim(click_df, item_emb_df, save_path, topk):\n",
    "    \"\"\"\n",
    "        基于内容的文章embedding相似性矩阵计算\n",
    "        :param click_df: 数据表\n",
    "        :param item_emb_df: 文章的embedding\n",
    "        :param save_path: 保存路径\n",
    "        :patam topk: 找最相似的topk篇\n",
    "        return 文章相似性矩阵\n",
    "        \n",
    "        思路: 对于每一篇文章， 基于embedding的相似性返回topk个与其最相似的文章， 只不过由于文章数量太多，这里用了faiss进行加速\n",
    "    \"\"\"\n",
    "    \n",
    "    # 文章索引与文章id的字典映射\n",
    "    item_idx_2_rawid_dict = dict(zip(item_emb_df.index, item_emb_df['article_id']))\n",
    "    \n",
    "    item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]\n",
    "    item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols].values, dtype=np.float32)\n",
    "    # 向量进行单位化\n",
    "    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)\n",
    "    \n",
    "    # 建立faiss索引\n",
    "    item_index = faiss.IndexFlatIP(item_emb_np.shape[1])\n",
    "    item_index.add(item_emb_np)\n",
    "    # 相似度查询，给每个索引位置上的向量返回topk个item以及相似度\n",
    "    sim, idx = item_index.search(item_emb_np, topk) # 返回的是列表\n",
    "    \n",
    "    # 将向量检索的结果保存成原始id的对应关系\n",
    "    item_sim_dict = collections.defaultdict(dict)\n",
    "    for target_idx, sim_value_list, rele_idx_list in tqdm(zip(range(len(item_emb_np)), sim, idx)):\n",
    "        target_raw_id = item_idx_2_rawid_dict[target_idx]\n",
    "        # 从1开始是为了去掉商品本身, 所以最终获得的相似商品只有topk-1\n",
    "        for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1:]): \n",
    "            rele_raw_id = item_idx_2_rawid_dict[rele_idx]\n",
    "            item_sim_dict[target_raw_id][rele_raw_id] = item_sim_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + sim_value\n",
    "    \n",
    "    # 保存i2i相似度矩阵\n",
    "    pickle.dump(item_sim_dict, open(save_path + 'emb_i2i_sim.pkl', 'wb'))   \n",
    "    \n",
    "    return item_sim_dict\n"
   ],
   "id": "299dc646855102ef",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:43:43.552317Z",
     "start_time": "2024-12-21T04:40:33.988505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "item_emb_df = pd.read_csv(data_path + '/articles_emb.csv')\n",
    "emb_i2i_sim = embdding_sim(all_click_df, item_emb_df, save_path, topk=10) # topk可以自行设置\n"
   ],
   "id": "9c2eb3748532875a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364047it [00:06, 55814.05it/s]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:43:43.568162Z",
     "start_time": "2024-12-21T04:43:43.555737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 基于商品的召回i2i\n",
    "def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim):\n",
    "    \"\"\"\n",
    "        基于文章协同过滤的召回\n",
    "        :param user_id: 用户id\n",
    "        :param user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列   {user1: {item1: time1, item2: time2..}...}\n",
    "        :param i2i_sim: 字典，文章相似性矩阵\n",
    "        :param sim_item_topk: 整数， 选择与当前文章最相似的前k篇文章\n",
    "        :param recall_item_num: 整数， 最后的召回文章数量\n",
    "        :param item_topk_click: 列表，点击次数最多的文章列表，用户召回补全\n",
    "        :param emb_i2i_sim: 字典基于内容embedding算的文章相似矩阵\n",
    "        \n",
    "        return: 召回的文章列表 {item1:score1, item2: score2...}\n",
    "        \n",
    "    \"\"\"\n",
    "    # 获取用户历史交互的文章\n",
    "    user_hist_items = user_item_time_dict[user_id]\n",
    "    \n",
    "    item_rank = {}\n",
    "    for loc, (i, click_time) in enumerate(user_hist_items):\n",
    "        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n",
    "            if j in user_hist_items:\n",
    "                continue\n",
    "            \n",
    "            # 文章创建时间差权重\n",
    "            created_time_weight = np.exp(0.5 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "            # 相似文章和历史点击文章序列中历史文章所在的位置权重\n",
    "            loc_weight = (0.9 ** (len(user_hist_items) - loc))\n",
    "            \n",
    "            content_weight = 1.0\n",
    "            if emb_i2i_sim.get(i, {}).get(j, None) is not None:\n",
    "                content_weight += emb_i2i_sim[i][j]\n",
    "            if emb_i2i_sim.get(j, {}).get(i, None) is not None:\n",
    "                content_weight += emb_i2i_sim[j][i]\n",
    "            content_weight = 1.0               \n",
    "            item_rank.setdefault(j, 0)\n",
    "            item_rank[j] += created_time_weight * loc_weight * content_weight * wij\n",
    "    \n",
    "    # 不足10个，用热门商品补全\n",
    "    if len(item_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in item_rank.items(): # 填充的item应该不在原来的列表中\n",
    "                continue\n",
    "            item_rank[item] = - i - 100 # 随便给个负数就行\n",
    "            if len(item_rank) == recall_item_num:\n",
    "                break\n",
    "    \n",
    "    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]\n",
    "        \n",
    "    return item_rank\n"
   ],
   "id": "dcb78ade5698b558",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:43:43.584164Z",
     "start_time": "2024-12-21T04:43:43.569163Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3c750a150d88d4b6",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:43:51.985481Z",
     "start_time": "2024-12-21T04:43:43.586162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 先进行itemcf召回, 为了召回评估，所以提取最后一次点击\n",
    "\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "\n",
    "trn_hist_click_df=trn_hist_click_df.sort_values(['user_id','click_timestamp'],ascending=[True,True])\n",
    "trn_hist_click_df= trn_hist_click_df.groupby('user_id').tail(3)\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "\n",
    "i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))\n",
    "emb_i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl', 'rb'))\n",
    "\n",
    "sim_item_topk = 20\n",
    "recall_item_num = 100\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=100)\n",
    "\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, \\\n",
    "                                                        i2i_sim, sim_item_topk, recall_item_num, \\\n",
    "                                                        item_topk_click, item_created_time_dict, emb_i2i_sim)\n",
    "\n",
    "user_multi_recall_dict['itemcf_sim_itemcf_recall'] = user_recall_items_dict\n",
    "pickle.dump(user_multi_recall_dict['itemcf_sim_itemcf_recall'], open(save_path + 'itemcf_recall_dict.pkl', 'wb'))\n",
    "\n",
    "if metric_recall:\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_multi_recall_dict['itemcf_sim_itemcf_recall'], trn_last_click_df, topk=recall_item_num)\n"
   ],
   "id": "84ec6f2d2c2f49d7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2495.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topk:  10  :  hit_num:  1386 hit_rate:  0.1386 user_num :  10000\n",
      " topk:  20  :  hit_num:  2020 hit_rate:  0.202 user_num :  10000\n",
      " topk:  30  :  hit_num:  2509 hit_rate:  0.2509 user_num :  10000\n",
      " topk:  40  :  hit_num:  2912 hit_rate:  0.2912 user_num :  10000\n",
      " topk:  50  :  hit_num:  3355 hit_rate:  0.3355 user_num :  10000\n",
      " topk:  60  :  hit_num:  3918 hit_rate:  0.3918 user_num :  10000\n",
      " topk:  70  :  hit_num:  4386 hit_rate:  0.4386 user_num :  10000\n",
      " topk:  80  :  hit_num:  4801 hit_rate:  0.4801 user_num :  10000\n",
      " topk:  90  :  hit_num:  5107 hit_rate:  0.5107 user_num :  10000\n",
      " topk:  100  :  hit_num:  5356 hit_rate:  0.5356 user_num :  10000\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:43:57.349764Z",
     "start_time": "2024-12-21T04:43:51.986482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这里是为了召回评估，所以提取最后一次点击\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl','rb'))\n",
    "\n",
    "sim_item_topk = 20\n",
    "recall_item_num = 50\n",
    "\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk, \n",
    "                                                        recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim)\n",
    "    \n",
    "user_multi_recall_dict['embedding_sim_item_recall'] = user_recall_items_dict\n",
    "pickle.dump(user_multi_recall_dict['embedding_sim_item_recall'], open(save_path + 'embedding_sim_item_recall.pkl', 'wb'))\n",
    "\n",
    "if metric_recall:\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_multi_recall_dict['embedding_sim_item_recall'], trn_last_click_df, topk=recall_item_num)\n"
   ],
   "id": "ae8237daf7d5adf2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 6858.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topk:  10  :  hit_num:  217 hit_rate:  0.0217 user_num :  10000\n",
      " topk:  20  :  hit_num:  659 hit_rate:  0.0659 user_num :  10000\n",
      " topk:  30  :  hit_num:  977 hit_rate:  0.0977 user_num :  10000\n",
      " topk:  40  :  hit_num:  1331 hit_rate:  0.1331 user_num :  10000\n",
      " topk:  50  :  hit_num:  1643 hit_rate:  0.1643 user_num :  10000\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:43:57.364898Z",
     "start_time": "2024-12-21T04:43:57.351752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 基于用户的召回 u2u2i\n",
    "def user_based_recommend(user_id, user_item_time_dict, u2u_sim, sim_user_topk, recall_item_num, \n",
    "                         item_topk_click, item_created_time_dict, emb_i2i_sim):\n",
    "    \"\"\"\n",
    "        基于文章协同过滤的召回\n",
    "        :param user_id: 用户id\n",
    "        :param user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列   {user1: {item1: time1, item2: time2..}...}\n",
    "        :param u2u_sim: 字典，文章相似性矩阵\n",
    "        :param sim_user_topk: 整数， 选择与当前用户最相似的前k个用户\n",
    "        :param recall_item_num: 整数， 最后的召回文章数量\n",
    "        :param item_topk_click: 列表，点击次数最多的文章列表，用户召回补全\n",
    "        :param item_created_time_dict: 文章创建时间列表\n",
    "        :param emb_i2i_sim: 字典基于内容embedding算的文章相似矩阵\n",
    "        \n",
    "        return: 召回的文章列表 {item1:score1, item2: score2...}\n",
    "    \"\"\"\n",
    "    # 历史交互\n",
    "    user_item_time_list = user_item_time_dict[user_id]    # {item1: time1, item2: time2...}\n",
    "    user_hist_items = set([i for i, t in user_item_time_list])   # 存在一个用户与某篇文章的多次交互， 这里得去重\n",
    "    \n",
    "    items_rank = {}\n",
    "    for sim_u, wuv in sorted(u2u_sim[user_id].items(), key=lambda x: x[1], reverse=True)[:sim_user_topk]:\n",
    "        for i, click_time in user_item_time_dict[sim_u]:\n",
    "            if i in user_hist_items:\n",
    "                continue\n",
    "            items_rank.setdefault(i, 0)\n",
    "            \n",
    "            loc_weight = 1.0\n",
    "            content_weight = 1.0\n",
    "            created_time_weight = 1.0\n",
    "            \n",
    "            # 当前文章与该用户看的历史文章进行一个权重交互\n",
    "            for loc, (j, click_time) in enumerate(user_item_time_list):\n",
    "                # 点击时的相对位置权重\n",
    "                loc_weight += 0.9 ** (len(user_item_time_list) - loc)\n",
    "                # 内容相似性权重\n",
    "                if emb_i2i_sim.get(i, {}).get(j, None) is not None:\n",
    "                    content_weight += emb_i2i_sim[i][j]\n",
    "                if emb_i2i_sim.get(j, {}).get(i, None) is not None:\n",
    "                    content_weight += emb_i2i_sim[j][i]\n",
    "                \n",
    "                # 创建时间差权重\n",
    "                created_time_weight += np.exp(0.8 * np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "                \n",
    "            items_rank[i] += loc_weight * content_weight * created_time_weight * wuv\n",
    "        \n",
    "    # 热度补全\n",
    "    if len(items_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in items_rank.items(): # 填充的item应该不在原来的列表中\n",
    "                continue\n",
    "            items_rank[item] = - i - 100 # 随便给个复数就行\n",
    "            if len(items_rank) == recall_item_num:\n",
    "                break\n",
    "        \n",
    "    items_rank = sorted(items_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]    \n",
    "    \n",
    "    return items_rank\n"
   ],
   "id": "5579c366e141cd0e",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:44:55.367379Z",
     "start_time": "2024-12-21T04:43:57.366896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这里是为了召回评估，所以提取最后一次点击\n",
    "# 由于usercf中计算user之间的相似度的过程太费内存了，全量数据这里就没有跑，跑了一个采样之后的数据\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "    \n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time(trn_hist_click_df)\n",
    "\n",
    "u2u_sim = pickle.load(open(save_path + 'usercf_u2u_sim.pkl', 'rb'))\n",
    "\n",
    "sim_user_topk = 20\n",
    "recall_item_num = 50\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = user_based_recommend(user, user_item_time_dict, u2u_sim, sim_user_topk, \\\n",
    "                                                        recall_item_num, item_topk_click, item_created_time_dict, emb_i2i_sim)    \n",
    "\n",
    "pickle.dump(user_recall_items_dict, open(save_path + 'usercf_u2u2i_recall.pkl', 'wb'))\n",
    "\n",
    "if metric_recall:\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_recall_items_dict, trn_last_click_df, topk=recall_item_num)\n"
   ],
   "id": "3377c8d8ad7eebd5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:53<00:00, 185.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topk:  10  :  hit_num:  1776 hit_rate:  0.1776 user_num :  10000\n",
      " topk:  20  :  hit_num:  2439 hit_rate:  0.2439 user_num :  10000\n",
      " topk:  30  :  hit_num:  2881 hit_rate:  0.2881 user_num :  10000\n",
      " topk:  40  :  hit_num:  3240 hit_rate:  0.324 user_num :  10000\n",
      " topk:  50  :  hit_num:  3496 hit_rate:  0.3496 user_num :  10000\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "新闻热度召回",
   "id": "26468791de063aa8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:56:44.016650Z",
     "start_time": "2024-12-21T04:56:44.008009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def hot_level_recall(all_click_df, user_id, topk=50, hours=1):\n",
    "    recall_time_range = all_click_df[all_click_df['user_id'] == user_id]['click_timestamp'].max() - 3600 * hours\n",
    "    df = all_click_df[all_click_df['click_timestamp'] > recall_time_range]\n",
    "\n",
    "    item_score_dict = collections.Counter(df['click_article_id'])\n",
    "    item_rank = sorted(item_score_dict.items(), key=lambda x: x[1], reverse=True)[:topk]\n",
    "    return item_rank\n",
    "\n"
   ],
   "id": "ce9fe9ae72cc2414",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T05:10:18.165188Z",
     "start_time": "2024-12-21T05:10:17.329089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_click_df = get_all_click_df(data_path)\n",
    "recall_time_range = all_click_df[all_click_df['user_id'] == 199971]['click_timestamp'].max() - 3600 * 1\n",
    "print(recall_time_range)\n",
    "print(all_click_df.info())\n",
    "print(all_click_df.describe())"
   ],
   "id": "1d001340be7f3afc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1507029663560\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1112623 entries, 0 to 1112622\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count    Dtype\n",
      "---  ------               --------------    -----\n",
      " 0   user_id              1112623 non-null  int64\n",
      " 1   click_article_id     1112623 non-null  int64\n",
      " 2   click_timestamp      1112623 non-null  int64\n",
      " 3   click_environment    1112623 non-null  int64\n",
      " 4   click_deviceGroup    1112623 non-null  int64\n",
      " 5   click_os             1112623 non-null  int64\n",
      " 6   click_country        1112623 non-null  int64\n",
      " 7   click_region         1112623 non-null  int64\n",
      " 8   click_referrer_type  1112623 non-null  int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 84.9 MB\n",
      "None\n",
      "            user_id  click_article_id  click_timestamp  click_environment  \\\n",
      "count  1.112623e+06      1.112623e+06     1.112623e+06       1.112623e+06   \n",
      "mean   1.221198e+05      1.951541e+05     1.507588e+12       3.947786e+00   \n",
      "std    5.540349e+04      9.292286e+04     3.363466e+08       3.276715e-01   \n",
      "min    0.000000e+00      3.000000e+00     1.507030e+12       1.000000e+00   \n",
      "25%    7.934700e+04      1.239090e+05     1.507297e+12       4.000000e+00   \n",
      "50%    1.309670e+05      2.038900e+05     1.507596e+12       4.000000e+00   \n",
      "75%    1.704010e+05      2.777120e+05     1.507841e+12       4.000000e+00   \n",
      "max    1.999990e+05      3.640460e+05     1.510603e+12       4.000000e+00   \n",
      "\n",
      "       click_deviceGroup      click_os  click_country  click_region  \\\n",
      "count       1.112623e+06  1.112623e+06   1.112623e+06  1.112623e+06   \n",
      "mean        1.815981e+00  1.301976e+01   1.310776e+00  1.813587e+01   \n",
      "std         1.035170e+00  6.967844e+00   1.618264e+00  7.105832e+00   \n",
      "min         1.000000e+00  2.000000e+00   1.000000e+00  1.000000e+00   \n",
      "25%         1.000000e+00  2.000000e+00   1.000000e+00  1.300000e+01   \n",
      "50%         1.000000e+00  1.700000e+01   1.000000e+00  2.100000e+01   \n",
      "75%         3.000000e+00  1.700000e+01   1.000000e+00  2.500000e+01   \n",
      "max         5.000000e+00  2.000000e+01   1.100000e+01  2.800000e+01   \n",
      "\n",
      "       click_referrer_type  \n",
      "count         1.112623e+06  \n",
      "mean          1.910063e+00  \n",
      "std           1.220012e+00  \n",
      "min           1.000000e+00  \n",
      "25%           1.000000e+00  \n",
      "50%           2.000000e+00  \n",
      "75%           2.000000e+00  \n",
      "max           7.000000e+00  \n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T07:49:34.422473Z",
     "start_time": "2024-12-21T05:18:39.978612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# 假设这些函数已经定义\n",
    "# get_all_click_sample(), get_hist_and_last_click(), hot_level_recall(), metrics_recall()\n",
    "\n",
    "all_click_df = get_all_click_df(data_path)\n",
    "\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "\n",
    "# 设置并行参数\n",
    "hours = 1\n",
    "recall_item_num = 50\n",
    "\n",
    "# 定义一个获取召回数据的函数\n",
    "def recall_for_user(user):\n",
    "    return user, hot_level_recall(trn_hist_click_df, user, recall_item_num, hours)\n",
    "\n",
    "# 使用 ThreadPoolExecutor 来并行处理\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # 提交任务\n",
    "    futures = {executor.submit(recall_for_user, user): user for user in trn_hist_click_df['user_id'].unique()}\n",
    "\n",
    "    # 获取并处理结果\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        user, recalled_items = future.result()\n",
    "        user_recall_items_dict[user] = recalled_items\n",
    "\n",
    "# 保存召回结果\n",
    "pickle.dump(user_recall_items_dict, open(save_path + 'hot_level_recall.pkl', 'wb'))\n",
    "\n",
    "# 召回效果评估\n",
    "if metric_recall:\n",
    "    metrics_recall(user_recall_items_dict, trn_last_click_df, topk=recall_item_num)\n"
   ],
   "id": "df891ff2843dc175",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [09:04<00:00, 367.52it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " topk:  10  :  hit_num:  23461 hit_rate:  0.11731 user_num :  200000\n",
      " topk:  20  :  hit_num:  36034 hit_rate:  0.18017 user_num :  200000\n",
      " topk:  30  :  hit_num:  45731 hit_rate:  0.22865 user_num :  200000\n",
      " topk:  40  :  hit_num:  53850 hit_rate:  0.26925 user_num :  200000\n",
      " topk:  50  :  hit_num:  61238 hit_rate:  0.30619 user_num :  200000\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T04:44:59.325585Z",
     "start_time": "2024-12-21T04:44:59.325585Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "be00f95730b4a42a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def combine_recall_results(user_multi_recall_dict, weight_dict=None, topk=25):\n",
    "    final_recall_items_dict = {}\n",
    "    \n",
    "    # 对每一种召回结果按照用户进行归一化，方便后面多种召回结果，相同用户的物品之间权重相加\n",
    "    def norm_user_recall_items_sim(sorted_item_list):\n",
    "        # 如果冷启动中没有文章或者只有一篇文章，直接返回，出现这种情况的原因可能是冷启动召回的文章数量太少了，\n",
    "        # 基于规则筛选之后就没有文章了, 这里还可以做一些其他的策略性的筛选\n",
    "        if len(sorted_item_list) < 2:\n",
    "            return sorted_item_list\n",
    "        \n",
    "        min_sim = sorted_item_list[-1][1]\n",
    "        max_sim = sorted_item_list[0][1]\n",
    "        \n",
    "        norm_sorted_item_list = []\n",
    "        for item, score in sorted_item_list:\n",
    "            if max_sim > 0:\n",
    "                norm_score = 1.0 * (score - min_sim) / (max_sim - min_sim) if max_sim > min_sim else 1.0\n",
    "            else:\n",
    "                norm_score = 0.0\n",
    "            norm_sorted_item_list.append((item, norm_score))\n",
    "            \n",
    "        return norm_sorted_item_list\n",
    "    \n",
    "    print('多路召回合并...')\n",
    "    for method, user_recall_items in tqdm(user_multi_recall_dict.items()):\n",
    "        print(method + '...')\n",
    "        # 在计算最终召回结果的时候，也可以为每一种召回结果设置一个权重\n",
    "        if weight_dict == None:\n",
    "            recall_method_weight = 1\n",
    "        else:\n",
    "            recall_method_weight = weight_dict[method]\n",
    "        \n",
    "        for user_id, sorted_item_list in user_recall_items.items(): # 进行归一化\n",
    "            user_recall_items[user_id] = norm_user_recall_items_sim(sorted_item_list)\n",
    "        \n",
    "        for user_id, sorted_item_list in user_recall_items.items():\n",
    "            # print('user_id')\n",
    "            final_recall_items_dict.setdefault(user_id, {})\n",
    "            for item, score in sorted_item_list:\n",
    "                final_recall_items_dict[user_id].setdefault(item, 0)\n",
    "                final_recall_items_dict[user_id][item] += recall_method_weight * score  \n",
    "    \n",
    "    final_recall_items_dict_rank = {}\n",
    "    # 多路召回时也可以控制最终的召回数量\n",
    "    for user, recall_item_dict in final_recall_items_dict.items():\n",
    "        final_recall_items_dict_rank[user] = sorted(recall_item_dict.items(), key=lambda x: x[1], reverse=True)[:topk]\n",
    "\n",
    "    # 将多路召回后的最终结果字典保存到本地\n",
    "    pickle.dump(final_recall_items_dict, open(os.path.join(save_path, 'final_recall_items_dict.pkl'),'wb'))\n",
    "\n",
    "    return final_recall_items_dict_rank\n"
   ],
   "id": "e826069c9eec9a19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 这里直接对多路召回的权重给了一个相同的值，其实可以根据前面召回的情况来调整参数的值\n",
    "weight_dict = {'itemcf_sim_itemcf_recall': 1.0,\n",
    "               'embedding_sim_item_recall': 1.0,\n",
    "               }\n"
   ],
   "id": "fa48ad6ba30ca236",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "31422bfe04f09387"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 最终合并之后每个用户召回150个商品进行排序\n",
    "final_recall_items_dict_rank = combine_recall_results(user_multi_recall_dict, weight_dict, topk=150)\n"
   ],
   "id": "d224847c47d5f3a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "23a0eda6eb1b4e5d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
